from pinecone import Pinecone, ServerlessSpec
import cohere
import os
from dotenv import load_dotenv
from data_loader import load_documents
import time

load_dotenv()

print("ğŸš€ Starting Pinecone embedding process...")

# Initialize Pinecone
print("Initializing Pinecone...")
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
print("âœ… Pinecone initialized")

# Initialize Cohere
print("Initializing Cohere...")
co = cohere.Client(api_key=os.getenv("COHERE_API_KEY"))
print("âœ… Cohere initialized")

# Load documents
print("\nLoading documents from data/holistic/...")
documents = load_documents("data/holistic")
print(f"âœ… Loaded {len(documents)} documents")

if len(documents) == 0:
    print("âŒ No documents found!")
    exit(1)

# Create or connect to index
index_name = "ombee-holistic"
print(f"\nChecking if index '{index_name}' exists...")

# Delete old index if exists
if index_name in pc.list_indexes().names():
    print("Found existing index, deleting...")
    pc.delete_index(index_name)
    print("âœ… Old index deleted")
    time.sleep(1)

# Create new index (1024 dimensions for Cohere embed-english-v3.0)
print("Creating new index...")
pc.create_index(
    name=index_name,
    dimension=1024,
    metric="cosine",
    spec=ServerlessSpec(
        cloud="aws",
        region="us-east-1"
    )
)
print("âœ… Index created (this may take a minute to initialize...)")

# Wait for index to be ready
time.sleep(5)

# Connect to index
index = pc.Index(index_name)
print(f"âœ… Connected to index")

# Embed documents
print(f"\nEmbedding {len(documents)} documents...")
texts = [doc['content'] for doc in documents]
ids = [doc['id'] for doc in documents]
sources = [doc['source'] for doc in documents]

print("  â†’ Calling Cohere API...")
response = co.embed(
    texts=texts,
    model="embed-english-v3.0",
    input_type="search_document"
)
embeddings = response.embeddings
print(f"  âœ… Got {len(embeddings)} embeddings")

# Upload to Pinecone
print(f"\nUploading {len(embeddings)} vectors to Pinecone...")

vectors_to_upsert = []
for i in range(len(embeddings)):
    vector_id = ids[i]
    vector_embedding = embeddings[i]
    vector_metadata = {
        "source": sources[i],
        "text": texts[i][:1000]  # Store first 1000 chars in metadata
    }
    
    vectors_to_upsert.append({
        "id": vector_id,
        "values": vector_embedding,
        "metadata": vector_metadata
    })
    print(f"  [{i+1}/{len(embeddings)}] Prepared: {sources[i]}")

print("\n  â†’ Uploading to Pinecone...")
index.upsert(vectors=vectors_to_upsert)
print("  âœ… Upload complete!")

# Verify
time.sleep(2)
stats = index.describe_index_stats()
print(f"\nâœ… Index stats: {stats['total_vector_count']} vectors stored")

print("\nğŸ‰ All documents embedded and uploaded to Pinecone!")
print(f"\nğŸŒ View your index at: https://app.pinecone.io/")